{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Price Prediction \n",
    "\n",
    "#### via Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " :Attribute Information (in order):\n",
    "- ```CRIM```:     per capita crime rate by town\n",
    "- ```ZN```:       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- ```INDUS```:    proportion of non-retail business acres per town\n",
    "- ```CHAS```:     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- ```NOX```:      nitric oxides concentration (parts per 10 million)\n",
    "- ```RM```:       average number of rooms per dwelling\n",
    "- ```AGE```:      proportion of owner-occupied units built prior to 1940\n",
    "- ```DIS```:      weighted distances to five Boston employment centres\n",
    "- ```RAD```:      index of accessibility to radial highways\n",
    "- ```TAX```:      full-value property-tax rate per $10,000$\n",
    "- ```PTRATIO```:  pupil-teacher ratio by town\n",
    "- ```B```:        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- ```LSTAT```:    % lower status of the population\n",
    "- ```MEDV```:     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
      "\n",
      "\n",
      "target\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      "\n",
      "\n",
      "feature_names\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "\n",
      "\n",
      "DESCR\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n",
      "\n",
      "\n",
      "filename\n",
      "/Users/jongwoop/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in boston.keys():\n",
    "    print(key)\n",
    "    print(boston[key])\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 13), dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston['data']\n",
    "print(X.shape)\n",
    "X[:0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = boston['target']\n",
    "print(y.shape)\n",
    "y[:0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(X, columns = boston['feature_names'])\n",
    "\n",
    "data['MEDV'] = y\n",
    "print(data.shape)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1 = X[:, 0] # CRIM\n",
    "x2 = X[:, 1] # ZN\n",
    "x3 = X[:, 2] # INDUS\n",
    "x4 = X[:, 3] # CHAS\n",
    "x5 = X[:, 4] # NOX\n",
    "x6 = X[:, 5] # RM\n",
    "x7 = X[:, 6] # AGE\n",
    "x8 = X[:, 7] # DIS\n",
    "x9 = X[:, 8] # RAD\n",
    "x10 = X[:, 9] # TAX\n",
    "x11 = X[:, 10] # PTRATIO\n",
    "x12 = X[:, 11] # B\n",
    "x13 = X[:, 12] # LSTAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, error = 388.356334\n",
      "1000, error = 7.472124\n",
      "2000, error = 7.043485\n",
      "3000, error = 6.775391\n",
      "4000, error = 6.560987\n",
      "5000, error = 6.373916\n",
      "6000, error = 6.210152\n",
      "7000, error = 6.068644\n",
      "8000, error = 5.948133\n",
      "9000, error = 5.839327\n",
      "10000, error = 5.747106\n",
      "11000, error = 5.663910\n",
      "12000, error = 5.589674\n",
      "13000, error = 5.522008\n",
      "14000, error = 5.460304\n",
      "15000, error = 5.402653\n",
      "16000, error = 5.349378\n",
      "17000, error = 5.299617\n",
      "18000, error = 5.254476\n",
      "19000, error = 5.212405\n",
      "20000, error = 5.173826\n",
      "21000, error = 5.139118\n",
      "22000, error = 5.107660\n",
      "23000, error = 5.078002\n",
      "24000, error = 5.050213\n",
      "25000, error = 5.024043\n",
      "--------------------------------------------------------------------------------\n",
      "25957, error = 4.999976\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 30000\n",
    "learning_rate = 0.000006\n",
    "\n",
    "w1 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w2 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w3 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w4 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w5 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w6 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w7 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w8 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w9 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w10 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w11 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w12 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "w13 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "\n",
    "b = np.random.uniform(low = -1.0, high = +1.0)\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    y_predict = (w1 * x1 + w2 * x2 + w3 * x3 + w4 * x4 + w5 * x5 \n",
    "                 + w6 * x6 + w7 * x7 + w8 * x8 + w9 * x9 + w10 * x10 \n",
    "                 + w11 * x11 + w12 * x12 + w13 * x13 + b)\n",
    "                 \n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    \n",
    "    if error < 5 : break\n",
    "    \n",
    "    if epoch % 1000 == 0: \n",
    "        print(f\"{epoch}, error = {error:.6f}\")\n",
    "    \n",
    "    w1 = w1 - learning_rate * ((y_predict - y) * x1).mean()\n",
    "    w2 = w2 - learning_rate * ((y_predict - y) * x2).mean()\n",
    "    w3 = w3 - learning_rate * ((y_predict - y) * x3).mean()\n",
    "    w4 = w4 - learning_rate * ((y_predict - y) * x4).mean()\n",
    "    w5 = w5 - learning_rate * ((y_predict - y) * x5).mean()\n",
    "    w6 = w6 - learning_rate * ((y_predict - y) * x6).mean()\n",
    "    w7 = w7 - learning_rate * ((y_predict - y) * x7).mean()\n",
    "    w8 = w8 - learning_rate * ((y_predict - y) * x8).mean()\n",
    "    w9 = w9 - learning_rate * ((y_predict - y) * x9).mean()\n",
    "    w10 = w10 - learning_rate * ((y_predict - y) * x10).mean()\n",
    "    w11 = w11 - learning_rate * ((y_predict - y) * x11).mean()\n",
    "    w12 = w12 - learning_rate * ((y_predict - y) * x12).mean()\n",
    "    w13 = w13 - learning_rate * ((y_predict - y) * x13).mean()\n",
    "\n",
    "    b = b - learning_rate * (y_predict - y).mean()\n",
    "\n",
    "print(\"----\" * 20)\n",
    "print(f\"{epoch}, error = {error:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = -0.080400, w2 = 0.071509, w3 = -0.104199, \n",
      "w4 = -0.778478, w5 = -0.490693, w6 = 1.239258, \n",
      "w7 = 0.123991, w8 = 0.531927, w9 = 0.008823, \n",
      "w10 = 0.007514, w11 = -0.044319, w12 = 0.032700, \n",
      "w13 = -0.715510, , b = -0.144563, error = 4.999976\n"
     ]
    }
   ],
   "source": [
    "print(f\"w1 = {w1:.6f}, w2 = {w2:.6f}, w3 = {w3:.6f}, \\n\"\n",
    "      f\"w4 = {w4:.6f}, w5 = {w5:.6f}, w6 = {w6:.6f}, \\n\"\n",
    "      f\"w7 = {w7:.6f}, w8 = {w8:.6f}, w9 = {w9:.6f}, \\n\"\n",
    "      f\"w10 = {w10:.6f}, w11 = {w11:.6f}, w12 = {w12:.6f}, \\n\"\n",
    "      f\"w13 = {w13:.6f}, , b = {b:.6f}, error = {error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent (using dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 506)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = np.array([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13])\n",
    "Xt = X.T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.02272633, -0.03449267, -0.09628946,  0.07310991, -0.07814278,\n",
       "       -0.07392611,  0.05093575, -0.04353965,  0.06711891,  0.04413253,\n",
       "        0.09733388, -0.00763456, -0.03115116])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# w1 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w2 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w3 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w4 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w5 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w6 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w7 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w8 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w9 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w10 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w11 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w12 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "# w13 = np.random.uniform(low = -1.0, high = +1.0)\n",
    "\n",
    "# w = np.array([w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, w11, w12, w13])\n",
    "\n",
    "w = np.array(np.random.uniform(low = -0.1, high = +0.1, size = 13))\n",
    "print(w.shape)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.013817296852326105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.uniform(low = -0.1, high = 0.1)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(X.dot(w).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "y_predict = X.dot(w) + b\n",
    "print(y_predict.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, error = 34.595690\n",
      "epoch = 10000, error = 5.667791\n",
      "epoch = 20000, error = 5.428729\n",
      "epoch = 30000, error = 5.321396\n",
      "epoch = 40000, error = 5.244022\n",
      "epoch = 50000, error = 5.175793\n",
      "epoch = 60000, error = 5.113663\n",
      "epoch = 70000, error = 5.058035\n",
      "epoch = 80000, error = 5.010369\n",
      "----------------------------------------\n",
      "epoch = 82336, error = 5.000000\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100000\n",
    "learning_rate = 0.000002\n",
    "\n",
    "w = np.array(np.random.uniform(low = -0.1, high = +0.1, size = 13))\n",
    "b = np.random.uniform(low = -0.1, high = 0.1)\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "   \n",
    "    y_predict = X.dot(w)  + b\n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    if error < 5: break\n",
    "    if epoch % 10000 == 0:\n",
    "        print(f\"epoch = {epoch}, error = {error:.6f}\")\n",
    "\n",
    "    w = w - learning_rate * ((y_predict - y).dot(X))/506\n",
    "    b = b - learning_rate * (y_predict - y).mean()\n",
    "\n",
    "    \n",
    "print(\"----\" * 10)\n",
    "print(f\"epoch = {epoch}, error = {error:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Gradient Descent\n",
    "# w1 = -0.042623, w2 = 0.161520, w3 = 0.241758, \n",
    "# w4 = 0.128965, w5 = -0.387602, w6 = 0.995259, \n",
    "# w7 = 0.069357, w8 = -0.921506, w9 = 0.203637, \n",
    "# w10 = -0.019277, w11 = 0.955265, w12 = 0.026578, \n",
    "# w13 = -0.881175, , b = 0.519338, error = 4.999995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 82336, w = [-0.08790236  0.10686106 -0.04460254  0.14220174 -0.06586741  0.71041924\n",
      "  0.11357433  0.04308015  0.08870802 -0.00160695  0.47406989  0.02973899\n",
      " -0.80316435], b = 0.000413, error = 5.000000\n"
     ]
    }
   ],
   "source": [
    "#From Dot product\n",
    "print(f\"epoch = {epoch}, w = {w}, b = {b:.6f}, error = {error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution from Lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w = np.random.uniform(low = -1.0, high = +1.0, size = (13,1))\n",
    "b = np.random.uniform(low = -1.0, high = +1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "0 error = 5.000000\n"
     ]
    }
   ],
   "source": [
    "## Solution from Lecture \n",
    "\n",
    "num_epoch = 10000\n",
    "learning_rate = 0.000003\n",
    "\n",
    "Xt = X.T #(13, 506)\n",
    "num_data = Xt.shape[1]\n",
    "\n",
    "w = np.random.uniform(low = -1.0, high = +1.0, size = (13,1))\n",
    "b = np.random.uniform(low = -1.0, high = +1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = np.dot(w.T, Xt) + b   #(1, 506), ysize = (506,)\n",
    "\n",
    "    if error < 5: break\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"{epoch} error = {error:.6f}\")\n",
    "        \n",
    "    w = w - learning_rate * np.dot(Xt, (y_predict - y).T) / num_data\n",
    "    b = b - learning_rate * np.dot(Xt, (y_predict - y).T).mean()\n",
    "\n",
    "print('----' * 10)\n",
    "print(f\"{epoch} error = {error:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.71806484e+05],\n",
       "       [4.22512484e+05],\n",
       "       [5.83264167e+05],\n",
       "       [3.63976485e+03],\n",
       "       [2.88642675e+04],\n",
       "       [3.24609699e+05],\n",
       "       [3.62398413e+06],\n",
       "       [1.94859169e+05],\n",
       "       [4.64847906e+05],\n",
       "       [2.06622921e+07],\n",
       "       [9.68687635e+05],\n",
       "       [1.98844296e+07],\n",
       "       [6.72125871e+05]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.dot(Xt, (y_predict - y).T).shape)\n",
    "np.dot(Xt, (y_predict - y).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.71806484e+05, 4.22512484e+05, 5.83264167e+05, 3.63976485e+03,\n",
       "        2.88642675e+04, 3.24609699e+05, 3.62398413e+06, 1.94859169e+05,\n",
       "        4.64847906e+05, 2.06622921e+07, 9.68687635e+05, 1.98844296e+07,\n",
       "        6.72125871e+05]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.dot((y_predict - y), X).shape)\n",
    "np.dot((y_predict - y), X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (506,13) and (506,506) not aligned: 13 (dim 1) != 506 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-efbd4ccb0375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (506,13) and (506,506) not aligned: 13 (dim 1) != 506 (dim 0)"
     ]
    }
   ],
   "source": [
    "num_epoch = 10000\n",
    "learning_rate = 0.000003\n",
    "\n",
    "w = np.random.uniform(low = -1.0, high = +1.0, size = (13,1))\n",
    "b = np.random.uniform(low = -1.0, high = +1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = X.T.dot(w) + b\n",
    "    \n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    w = w - learning_rate * X.T.dot(y_predict - y) / len(X)\n",
    "    b = b - learning_rate * (y_predict - y).mean()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(epoch, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(X.T.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 506)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
